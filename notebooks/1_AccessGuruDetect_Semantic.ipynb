{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-bwLFBqcrt_V"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  AccessGuru Detect Notebook\n",
        "Full Pipline:\n",
        "1. **AccessGuruDetect SyntaxLayout**: Detect violations (Axe-Playwright) [Notebook Link](https://colab.research.google.com/drive/1edKtrSCJ2FrZqU0G8v9424yKG-qQrrRU?usp=sharing)\n",
        "2. **AccessGuruDetect Semantic**: Detect violations (LLM)[Current Notebook]\n",
        "3. **AccessGuruCorrect**: Generate corrections using LLM prompting strategies. [Notebook Link](https://colab.research.google.com/drive/1zoW8fL6VLz1sE8BoHbfnIaaOrgMeNKC5?usp=drive_link)\n",
        "\n",
        "This notebook demonstrates a full pipeline for **AccessGuruDetect**: Detect violations (Axe-Playwright + LLM)\n",
        "We’ll walk through each step with explanations and runnable code."
      ],
      "metadata": {
        "id": "sn944O7krgrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. AccessGuruDetect\n",
        "We implemented the AccessGuruDetect using\n",
        "Axe-Playwright-1.51.0 for syntax and layout accessibility\n",
        "violations."
      ],
      "metadata": {
        "id": "NSR-QGrPrseD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Install Dependencies\n",
        "Use \"pip install\" to install the package"
      ],
      "metadata": {
        "id": "-bwLFBqcrt_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install playwright\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "moi2He7DSR6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153f0f98-96aa-47ed-e1ab-a30f71eb847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playwright\n",
            "  Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting pyee<14,>=13 (from playwright)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from pyee<14,>=13->playwright) (4.15.0)\n",
            "Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.55.0 pyee-13.0.0\n",
            "Downloading Chromium 140.0.7339.16 (playwright build v1187)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1187/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G173.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 0% 52.9s\u001b[0K\u001b[1G173.7 MiB [] 0% 23.8s\u001b[0K\u001b[1G173.7 MiB [] 0% 15.0s\u001b[0K\u001b[1G173.7 MiB [] 0% 7.7s\u001b[0K\u001b[1G173.7 MiB [] 1% 5.0s\u001b[0K\u001b[1G173.7 MiB [] 2% 3.9s\u001b[0K\u001b[1G173.7 MiB [] 3% 3.2s\u001b[0K\u001b[1G173.7 MiB [] 4% 2.8s\u001b[0K\u001b[1G173.7 MiB [] 5% 2.9s\u001b[0K\u001b[1G173.7 MiB [] 5% 2.7s\u001b[0K\u001b[1G173.7 MiB [] 6% 2.6s\u001b[0K\u001b[1G173.7 MiB [] 7% 2.6s\u001b[0K\u001b[1G173.7 MiB [] 8% 2.4s\u001b[0K\u001b[1G173.7 MiB [] 9% 2.4s\u001b[0K\u001b[1G173.7 MiB [] 9% 2.3s\u001b[0K\u001b[1G173.7 MiB [] 10% 2.2s\u001b[0K\u001b[1G173.7 MiB [] 12% 2.1s\u001b[0K\u001b[1G173.7 MiB [] 13% 2.0s\u001b[0K\u001b[1G173.7 MiB [] 14% 1.9s\u001b[0K\u001b[1G173.7 MiB [] 16% 1.8s\u001b[0K\u001b[1G173.7 MiB [] 17% 1.7s\u001b[0K\u001b[1G173.7 MiB [] 18% 1.7s\u001b[0K\u001b[1G173.7 MiB [] 19% 1.6s\u001b[0K\u001b[1G173.7 MiB [] 20% 1.6s\u001b[0K\u001b[1G173.7 MiB [] 22% 1.5s\u001b[0K\u001b[1G173.7 MiB [] 23% 1.5s\u001b[0K\u001b[1G173.7 MiB [] 24% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 25% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 25% 1.5s\u001b[0K\u001b[1G173.7 MiB [] 26% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 28% 1.4s\u001b[0K\u001b[1G173.7 MiB [] 29% 1.3s\u001b[0K\u001b[1G173.7 MiB [] 31% 1.3s\u001b[0K\u001b[1G173.7 MiB [] 32% 1.2s\u001b[0K\u001b[1G173.7 MiB [] 34% 1.2s\u001b[0K\u001b[1G173.7 MiB [] 35% 1.1s\u001b[0K\u001b[1G173.7 MiB [] 37% 1.1s\u001b[0K\u001b[1G173.7 MiB [] 38% 1.1s\u001b[0K\u001b[1G173.7 MiB [] 39% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 40% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 42% 1.0s\u001b[0K\u001b[1G173.7 MiB [] 43% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 44% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 45% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 47% 0.9s\u001b[0K\u001b[1G173.7 MiB [] 48% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 50% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 51% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 52% 0.8s\u001b[0K\u001b[1G173.7 MiB [] 53% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 54% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 55% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 56% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 57% 0.7s\u001b[0K\u001b[1G173.7 MiB [] 58% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 59% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 60% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 61% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 63% 0.6s\u001b[0K\u001b[1G173.7 MiB [] 64% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 65% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 66% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 67% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 68% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 69% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 70% 0.5s\u001b[0K\u001b[1G173.7 MiB [] 71% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 72% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 73% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 74% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 75% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 76% 0.4s\u001b[0K\u001b[1G173.7 MiB [] 77% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 78% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 80% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 81% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 82% 0.3s\u001b[0K\u001b[1G173.7 MiB [] 84% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 85% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 86% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 88% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 89% 0.2s\u001b[0K\u001b[1G173.7 MiB [] 90% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 92% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 93% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G173.7 MiB [] 97% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 99% 0.0s\u001b[0K\u001b[1G173.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 140.0.7339.16 (playwright build v1187) downloaded to /root/.cache/ms-playwright/chromium-1187\n",
            "Downloading Chromium Headless Shell 140.0.7339.16 (playwright build v1187)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1187/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G104.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 0% 30.0s\u001b[0K\u001b[1G104.3 MiB [] 0% 15.1s\u001b[0K\u001b[1G104.3 MiB [] 0% 9.8s\u001b[0K\u001b[1G104.3 MiB [] 1% 4.6s\u001b[0K\u001b[1G104.3 MiB [] 2% 2.8s\u001b[0K\u001b[1G104.3 MiB [] 3% 2.4s\u001b[0K\u001b[1G104.3 MiB [] 5% 1.9s\u001b[0K\u001b[1G104.3 MiB [] 6% 1.9s\u001b[0K\u001b[1G104.3 MiB [] 7% 2.0s\u001b[0K\u001b[1G104.3 MiB [] 8% 1.8s\u001b[0K\u001b[1G104.3 MiB [] 9% 1.8s\u001b[0K\u001b[1G104.3 MiB [] 9% 1.9s\u001b[0K\u001b[1G104.3 MiB [] 11% 1.9s\u001b[0K\u001b[1G104.3 MiB [] 13% 1.6s\u001b[0K\u001b[1G104.3 MiB [] 15% 1.5s\u001b[0K\u001b[1G104.3 MiB [] 16% 1.4s\u001b[0K\u001b[1G104.3 MiB [] 18% 1.4s\u001b[0K\u001b[1G104.3 MiB [] 20% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 21% 1.2s\u001b[0K\u001b[1G104.3 MiB [] 23% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 25% 1.1s\u001b[0K\u001b[1G104.3 MiB [] 27% 1.0s\u001b[0K\u001b[1G104.3 MiB [] 29% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 32% 0.9s\u001b[0K\u001b[1G104.3 MiB [] 34% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 35% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 37% 0.8s\u001b[0K\u001b[1G104.3 MiB [] 39% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 41% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 43% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 45% 0.7s\u001b[0K\u001b[1G104.3 MiB [] 47% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 49% 0.6s\u001b[0K\u001b[1G104.3 MiB [] 52% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 54% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 56% 0.5s\u001b[0K\u001b[1G104.3 MiB [] 58% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 60% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 62% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 64% 0.4s\u001b[0K\u001b[1G104.3 MiB [] 67% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 69% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 71% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 74% 0.3s\u001b[0K\u001b[1G104.3 MiB [] 76% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 79% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 82% 0.2s\u001b[0K\u001b[1G104.3 MiB [] 84% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 87% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 89% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 91% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G104.3 MiB [] 96% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 99% 0.0s\u001b[0K\u001b[1G104.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 140.0.7339.16 (playwright build v1187) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1187\n",
            "Downloading Firefox 141.0 (playwright build v1490)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1490/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G96 MiB [] 0% 0.0s\u001b[0K\u001b[1G96 MiB [] 0% 30.8s\u001b[0K\u001b[1G96 MiB [] 0% 51.9s\u001b[0K\u001b[1G96 MiB [] 0% 52.6s\u001b[0K\u001b[1G96 MiB [] 0% 54.7s\u001b[0K\u001b[1G96 MiB [] 0% 54.8s\u001b[0K\u001b[1G96 MiB [] 0% 55.1s\u001b[0K\u001b[1G96 MiB [] 0% 55.5s\u001b[0K\u001b[1G96 MiB [] 0% 55.4s\u001b[0K\u001b[1G96 MiB [] 0% 55.7s\u001b[0K\u001b[1G96 MiB [] 0% 56.5s\u001b[0K\u001b[1G96 MiB [] 0% 56.4s\u001b[0K\u001b[1G96 MiB [] 1% 56.4s\u001b[0K\u001b[1G96 MiB [] 1% 56.1s\u001b[0K\u001b[1G96 MiB [] 1% 58.1s\u001b[0K\u001b[1G96 MiB [] 1% 57.9s\u001b[0K\u001b[1G96 MiB [] 1% 57.8s\u001b[0K\u001b[1G96 MiB [] 1% 57.7s\u001b[0K\u001b[1G96 MiB [] 1% 58.0s\u001b[0K\u001b[1G96 MiB [] 1% 57.7s\u001b[0K\u001b[1G96 MiB [] 1% 57.3s\u001b[0K\u001b[1G96 MiB [] 1% 57.1s\u001b[0K\u001b[1G96 MiB [] 1% 57.0s\u001b[0K\u001b[1G96 MiB [] 1% 56.9s\u001b[0K\u001b[1G96 MiB [] 1% 56.8s\u001b[0K\u001b[1G96 MiB [] 1% 56.7s\u001b[0K\u001b[1G96 MiB [] 2% 56.6s\u001b[0K\u001b[1G96 MiB [] 2% 56.5s\u001b[0K\u001b[1G96 MiB [] 2% 56.4s\u001b[0K\u001b[1G96 MiB [] 2% 56.3s\u001b[0K\u001b[1G96 MiB [] 2% 56.5s\u001b[0K\u001b[1G96 MiB [] 2% 56.1s\u001b[0K\u001b[1G96 MiB [] 2% 56.0s\u001b[0K\u001b[1G96 MiB [] 2% 55.9s\u001b[0K\u001b[1G96 MiB [] 2% 55.8s\u001b[0K\u001b[1G96 MiB [] 2% 55.9s\u001b[0K\u001b[1G96 MiB [] 2% 55.8s\u001b[0K\u001b[1G96 MiB [] 3% 55.7s\u001b[0K\u001b[1G96 MiB [] 3% 55.6s\u001b[0K\u001b[1G96 MiB [] 3% 55.9s\u001b[0K\u001b[1G96 MiB [] 3% 55.4s\u001b[0K\u001b[1G96 MiB [] 3% 55.5s\u001b[0K\u001b[1G96 MiB [] 3% 55.4s\u001b[0K\u001b[1G96 MiB [] 3% 55.3s\u001b[0K\u001b[1G96 MiB [] 3% 55.2s\u001b[0K\u001b[1G96 MiB [] 3% 55.1s\u001b[0K\u001b[1G96 MiB [] 3% 54.6s\u001b[0K\u001b[1G96 MiB [] 4% 43.5s\u001b[0K\u001b[1G96 MiB [] 5% 34.2s\u001b[0K\u001b[1G96 MiB [] 7% 28.6s\u001b[0K\u001b[1G96 MiB [] 8% 25.0s\u001b[0K\u001b[1G96 MiB [] 9% 21.8s\u001b[0K\u001b[1G96 MiB [] 9% 21.7s\u001b[0K\u001b[1G96 MiB [] 10% 20.1s\u001b[0K\u001b[1G96 MiB [] 11% 18.2s\u001b[0K\u001b[1G96 MiB [] 11% 17.4s\u001b[0K\u001b[1G96 MiB [] 12% 16.0s\u001b[0K\u001b[1G96 MiB [] 13% 14.5s\u001b[0K\u001b[1G96 MiB [] 15% 12.9s\u001b[0K\u001b[1G96 MiB [] 15% 12.4s\u001b[0K\u001b[1G96 MiB [] 16% 11.7s\u001b[0K\u001b[1G96 MiB [] 17% 11.2s\u001b[0K\u001b[1G96 MiB [] 19% 10.1s\u001b[0K\u001b[1G96 MiB [] 20% 9.2s\u001b[0K\u001b[1G96 MiB [] 22% 8.5s\u001b[0K\u001b[1G96 MiB [] 23% 8.1s\u001b[0K\u001b[1G96 MiB [] 24% 7.5s\u001b[0K\u001b[1G96 MiB [] 25% 7.2s\u001b[0K\u001b[1G96 MiB [] 27% 6.7s\u001b[0K\u001b[1G96 MiB [] 28% 6.3s\u001b[0K\u001b[1G96 MiB [] 30% 5.9s\u001b[0K\u001b[1G96 MiB [] 31% 5.6s\u001b[0K\u001b[1G96 MiB [] 32% 5.3s\u001b[0K\u001b[1G96 MiB [] 33% 5.0s\u001b[0K\u001b[1G96 MiB [] 35% 4.8s\u001b[0K\u001b[1G96 MiB [] 36% 4.6s\u001b[0K\u001b[1G96 MiB [] 36% 4.5s\u001b[0K\u001b[1G96 MiB [] 37% 4.4s\u001b[0K\u001b[1G96 MiB [] 38% 4.3s\u001b[0K\u001b[1G96 MiB [] 39% 4.0s\u001b[0K\u001b[1G96 MiB [] 41% 3.9s\u001b[0K\u001b[1G96 MiB [] 42% 3.6s\u001b[0K\u001b[1G96 MiB [] 44% 3.4s\u001b[0K\u001b[1G96 MiB [] 46% 3.2s\u001b[0K\u001b[1G96 MiB [] 47% 3.1s\u001b[0K\u001b[1G96 MiB [] 48% 3.1s\u001b[0K\u001b[1G96 MiB [] 49% 2.9s\u001b[0K\u001b[1G96 MiB [] 51% 2.7s\u001b[0K\u001b[1G96 MiB [] 53% 2.5s\u001b[0K\u001b[1G96 MiB [] 55% 2.3s\u001b[0K\u001b[1G96 MiB [] 57% 2.2s\u001b[0K\u001b[1G96 MiB [] 59% 2.0s\u001b[0K\u001b[1G96 MiB [] 60% 1.9s\u001b[0K\u001b[1G96 MiB [] 62% 1.7s\u001b[0K\u001b[1G96 MiB [] 64% 1.6s\u001b[0K\u001b[1G96 MiB [] 66% 1.5s\u001b[0K\u001b[1G96 MiB [] 68% 1.4s\u001b[0K\u001b[1G96 MiB [] 70% 1.3s\u001b[0K\u001b[1G96 MiB [] 71% 1.2s\u001b[0K\u001b[1G96 MiB [] 73% 1.1s\u001b[0K\u001b[1G96 MiB [] 75% 1.0s\u001b[0K\u001b[1G96 MiB [] 76% 0.9s\u001b[0K\u001b[1G96 MiB [] 78% 0.8s\u001b[0K\u001b[1G96 MiB [] 80% 0.8s\u001b[0K\u001b[1G96 MiB [] 82% 0.7s\u001b[0K\u001b[1G96 MiB [] 84% 0.6s\u001b[0K\u001b[1G96 MiB [] 85% 0.5s\u001b[0K\u001b[1G96 MiB [] 87% 0.5s\u001b[0K\u001b[1G96 MiB [] 89% 0.4s\u001b[0K\u001b[1G96 MiB [] 91% 0.3s\u001b[0K\u001b[1G96 MiB [] 92% 0.3s\u001b[0K\u001b[1G96 MiB [] 93% 0.2s\u001b[0K\u001b[1G96 MiB [] 95% 0.2s\u001b[0K\u001b[1G96 MiB [] 97% 0.1s\u001b[0K\u001b[1G96 MiB [] 99% 0.0s\u001b[0K\u001b[1G96 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 141.0 (playwright build v1490) downloaded to /root/.cache/ms-playwright/firefox-1490\n",
            "Downloading Webkit 26.0 (playwright build v2203)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2203/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G94.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 0% 24.4s\u001b[0K\u001b[1G94.6 MiB [] 0% 11.4s\u001b[0K\u001b[1G94.6 MiB [] 0% 7.2s\u001b[0K\u001b[1G94.6 MiB [] 1% 7.9s\u001b[0K\u001b[1G94.6 MiB [] 1% 8.1s\u001b[0K\u001b[1G94.6 MiB [] 1% 8.2s\u001b[0K\u001b[1G94.6 MiB [] 2% 7.4s\u001b[0K\u001b[1G94.6 MiB [] 2% 6.9s\u001b[0K\u001b[1G94.6 MiB [] 3% 5.2s\u001b[0K\u001b[1G94.6 MiB [] 4% 4.6s\u001b[0K\u001b[1G94.6 MiB [] 6% 3.7s\u001b[0K\u001b[1G94.6 MiB [] 7% 3.1s\u001b[0K\u001b[1G94.6 MiB [] 9% 2.7s\u001b[0K\u001b[1G94.6 MiB [] 10% 2.6s\u001b[0K\u001b[1G94.6 MiB [] 11% 2.5s\u001b[0K\u001b[1G94.6 MiB [] 12% 2.3s\u001b[0K\u001b[1G94.6 MiB [] 13% 2.2s\u001b[0K\u001b[1G94.6 MiB [] 14% 2.1s\u001b[0K\u001b[1G94.6 MiB [] 16% 1.9s\u001b[0K\u001b[1G94.6 MiB [] 17% 2.0s\u001b[0K\u001b[1G94.6 MiB [] 18% 1.9s\u001b[0K\u001b[1G94.6 MiB [] 20% 1.7s\u001b[0K\u001b[1G94.6 MiB [] 22% 1.6s\u001b[0K\u001b[1G94.6 MiB [] 23% 1.6s\u001b[0K\u001b[1G94.6 MiB [] 25% 1.5s\u001b[0K\u001b[1G94.6 MiB [] 26% 1.5s\u001b[0K\u001b[1G94.6 MiB [] 27% 1.4s\u001b[0K\u001b[1G94.6 MiB [] 29% 1.3s\u001b[0K\u001b[1G94.6 MiB [] 31% 1.3s\u001b[0K\u001b[1G94.6 MiB [] 33% 1.2s\u001b[0K\u001b[1G94.6 MiB [] 35% 1.1s\u001b[0K\u001b[1G94.6 MiB [] 37% 1.1s\u001b[0K\u001b[1G94.6 MiB [] 38% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 39% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 40% 1.0s\u001b[0K\u001b[1G94.6 MiB [] 42% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 44% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 46% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 48% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 49% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 49% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 50% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 50% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 51% 0.9s\u001b[0K\u001b[1G94.6 MiB [] 52% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 53% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 54% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 55% 0.8s\u001b[0K\u001b[1G94.6 MiB [] 57% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 58% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 60% 0.7s\u001b[0K\u001b[1G94.6 MiB [] 62% 0.6s\u001b[0K\u001b[1G94.6 MiB [] 64% 0.6s\u001b[0K\u001b[1G94.6 MiB [] 66% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 68% 0.5s\u001b[0K\u001b[1G94.6 MiB [] 70% 0.4s\u001b[0K\u001b[1G94.6 MiB [] 72% 0.4s\u001b[0K\u001b[1G94.6 MiB [] 74% 0.4s\u001b[0K\u001b[1G94.6 MiB [] 76% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 78% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 80% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 82% 0.3s\u001b[0K\u001b[1G94.6 MiB [] 83% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 84% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 86% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 87% 0.2s\u001b[0K\u001b[1G94.6 MiB [] 89% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 91% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 93% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 95% 0.1s\u001b[0K\u001b[1G94.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G94.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 26.0 (playwright build v2203) downloaded to /root/.cache/ms-playwright/webkit-2203\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 2% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 10% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 24% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 61% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:934:14)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:1056:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/server/registry/index.js:1045:7)\n",
            "    at async i.<anonymous> (/usr/local/lib/python3.12/dist-packages/playwright/driver/package/lib/cli/program.js:217:7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wget\n",
        "! pip install selenium"
      ],
      "metadata": {
        "id": "t5ekZghxrv1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6549db06-63ec-4d32-f09a-42ba176ec8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=71e47171c926e7210ba631335c2a11487793961d99f0535c011823934a2ec00c\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Collecting typing_extensions~=4.14.0 (from selenium)\n",
            "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, typing_extensions, outcome, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Imports & Setup"
      ],
      "metadata": {
        "id": "zV-XrXl9rynk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "\n",
        "import wget\n",
        "import requests\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import pandas as pd\n",
        "import base64\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "jZq3Repory46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output directories\n",
        "output_dir = \"/content/html_pages_async\"\n",
        "screenshot_dir = \"/content/element_screenshots\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(screenshot_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "b-dimC4Wr1WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required data(violation taxonomy, mapping dictionary) from AccessGuru Repo\n",
        "! wget 'https://raw.githubusercontent.com/NadeenAhmad/AccessGuruLLM/refs/heads/main/data/prompts_support/violation_taxonomy.csv'\n",
        "! wget 'https://raw.githubusercontent.com/NadeenAhmad/AccessGuruLLM/refs/heads/main/data/prompts_support/mapping_dict_file.json'\n",
        "! wget 'https://raw.githubusercontent.com/NadeenAhmad/AccessGuruLLM/refs/heads/main/data/prompts_support/violations_short_description.json'"
      ],
      "metadata": {
        "id": "Wy5qfgLnr2Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_dict_path = '/content/mapping_dict_file.json'\n",
        "with open(mapping_dict_path, 'r') as file:\n",
        "  mapping_dict = json.load(file)\n",
        "\n",
        "violation_description_path = '/content/violations_short_description.json'\n",
        "with open(violation_description_path, 'r') as file:\n",
        "  violation_description_dict = json.load(file)\n",
        "\n",
        "taxonomy_path = \"/content/violation_taxonomy.csv\"\n",
        "cat_data = pd.read_csv(taxonomy_path)\n"
      ],
      "metadata": {
        "id": "lPOKPnFfr3lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impactScore = {\n",
        "  \"critical\": 5,\n",
        "  \"serious\": 4,\n",
        "  \"moderate\": 3,\n",
        "  \"minor\": 2,\n",
        "  \"cosmetic\": 1,\n",
        "}\n",
        "\n",
        "impact_dict = {\n",
        "      'image-alt-not-descriptive': 'critical',\n",
        "      'video-captions-not-descriptive': 'critical',\n",
        "      'lang-mismatch': 'serious',\n",
        "      'missing-lang-tag': 'serious',\n",
        "      'link-text-mismatch': 'serious',\n",
        "      'button-label-mismatch': 'critical',\n",
        "      'form-label-mismatch': 'critical',\n",
        "      'ambiguous-heading': 'moderate',\n",
        "      'incorrect-semantic-tag': 'serious',\n",
        "      'landmark-structural-violation': 'serious',\n",
        "      'landmark-purpose-mismatch': 'serious',\n",
        "      'page-title-not-descriptive': 'serious',\n",
        "      'autocomplete-purpose-mismatch': 'serious',\n",
        "      'color-only-distinction': 'serious',\n",
        "      'illogical-focus-order': 'serious',\n",
        "      'label-name-mismatch': 'serious'\n",
        "       }"
      ],
      "metadata": {
        "id": "6NIOH0zUsPbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Utility Functions\n",
        "modules needed for the Detection:\n",
        "*   Download images,\n",
        "*   Check if given URL can be scraped\n",
        "*   save scraped HTML code,\n",
        "*   supplementary information extraction ."
      ],
      "metadata": {
        "id": "T6BoCRU3r44i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def save_html(html, url):\n",
        "    parsed = urlparse(url)\n",
        "    netloc = parsed.netloc.replace(\".\", \"_\")\n",
        "    path = parsed.path.strip(\"/\") or \"home\"\n",
        "    path = \"\".join([c if c.isalnum() else \"_\" for c in path])\n",
        "    file_name = f\"{netloc}_{path}.html\"\n",
        "    file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html)\n",
        "\n",
        "    return file_path\n",
        "\n",
        "async def url_check(url):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch()\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        try:\n",
        "            # Try navigating with a timeout\n",
        "            response = await page.goto(url, timeout=15000, wait_until=\"domcontentloaded\")\n",
        "\n",
        "            if not response:\n",
        "                print(f'No response for {url}. Please try another URL')\n",
        "                return \"not scraped\"\n",
        "\n",
        "            status = response.status\n",
        "            final_url = page.url\n",
        "\n",
        "            if status >= 400:\n",
        "                print(f\"Failed to load {url} (status {status}). Please try another URL\")\n",
        "                return \"not scraped\"\n",
        "\n",
        "            print(f\"Loaded {final_url} (status {status})\")\n",
        "            scrape_status = \"scraped\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {url}. Please try another URL\")\n",
        "            return \"not scraped\"\n",
        "        finally:\n",
        "            await browser.close()\n",
        "\n",
        "\n",
        "def find_matching_ul(soup, snippet_html):\n",
        "    snippet_soup = BeautifulSoup(snippet_html, 'html.parser')\n",
        "    snippet_ul = snippet_soup.find('ul')\n",
        "    if not snippet_ul:\n",
        "        return None\n",
        "\n",
        "    snippet_classes = set(snippet_ul.get('class', []))\n",
        "\n",
        "    for ul in soup.find_all('ul'):\n",
        "        ul_classes = set(ul.get('class', []))\n",
        "        if snippet_classes.issubset(ul_classes):\n",
        "            return str(ul)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_landmark_container_for_tag(soup, tag_name='main'):\n",
        "    tag = soup.find(lambda tag: tag.name == tag_name or tag.get('role', '').lower() == tag_name)\n",
        "    if not tag:\n",
        "        return None, f\"No <{tag_name}> tag or role='{tag_name}' found\"\n",
        "\n",
        "    landmark_roles = {'banner', 'complementary', 'main', 'contentinfo', 'navigation', 'region'}\n",
        "    current = tag.parent\n",
        "\n",
        "    while current:\n",
        "        role = current.get('role', '').lower()\n",
        "        if role in landmark_roles or current.name in landmark_roles:\n",
        "            return current, None\n",
        "        current = current.parent if hasattr(current, 'parent') else None\n",
        "\n",
        "    return tag, None\n",
        "\n",
        "\n",
        "def role_or_tag(role_value, tag_name):\n",
        "    return lambda tag: tag.name == tag_name or tag.attrs.get(\"role\") == role_value\n",
        "\n",
        "def get_full_list_html(web_html: str, affected_html: str) -> str | None:\n",
        "    soup = BeautifulSoup(web_html, \"html.parser\")\n",
        "\n",
        "    # Parse the affected HTML to extract the tag and attributes\n",
        "    affected_soup = BeautifulSoup(affected_html, \"html.parser\")\n",
        "    affected_element = affected_soup.find()\n",
        "\n",
        "    if not affected_element:\n",
        "        print(\"Could not parse affected HTML\")\n",
        "        return None\n",
        "\n",
        "    # Find matching element in full page HTML\n",
        "    matches = soup.find_all(affected_element.name, attrs=affected_element.attrs)\n",
        "\n",
        "    for match in matches:\n",
        "        # Return the outer HTML of the matching list\n",
        "        if match.name in ['ul', 'ol']:\n",
        "            return str(match)\n",
        "\n",
        "    print(\"No matching full list element found.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- Parse <style> blocks into a {selector -> {prop: value}} index ---\n",
        "def parse_css_rules_from_style_tags(full_html: str):\n",
        "    soup = BeautifulSoup(full_html, \"html.parser\")\n",
        "    css_text = \"\\n\".join(st.get_text() for st in soup.find_all(\"style\"))\n",
        "    rules = {}  # selector -> {prop: value}\n",
        "\n",
        "    # Very simple CSS parser: selector { prop:value; ... }\n",
        "    for selectors, props in re.findall(r'([^{]+)\\{([^}]+)\\}', css_text, re.DOTALL):\n",
        "        # parse props\n",
        "        props_dict = {}\n",
        "        for k, v in re.findall(r'([-\\w]+)\\s*:\\s*([^;]+);?', props):\n",
        "            props_dict[k.strip().lower()] = v.strip()\n",
        "        # split combined selectors: #id, .class, span, etc.\n",
        "        for sel in selectors.split(\",\"):\n",
        "            sel = sel.strip()\n",
        "            if sel:\n",
        "                # last rule wins; overwrite\n",
        "                rules[sel] = {**rules.get(sel, {}), **props_dict}\n",
        "    return rules\n",
        "\n",
        "# --- Inline style -> dict ---\n",
        "def parse_inline_style(style_str: str):\n",
        "    out = {}\n",
        "    for k, v in re.findall(r'([-\\w]+)\\s*:\\s*([^;]+);?', style_str or \"\"):\n",
        "        out[k.strip().lower()] = v.strip()\n",
        "    return out\n",
        "\n",
        "# --- Try to locate the snippet tag inside the full DOM (id > class > text) ---\n",
        "def locate_in_full_html(snippet_tag, full_soup: BeautifulSoup):\n",
        "    if snippet_tag.has_attr(\"id\"):\n",
        "        found = full_soup.find(id=snippet_tag[\"id\"])\n",
        "        if found: return found\n",
        "\n",
        "    if snippet_tag.has_attr(\"class\"):\n",
        "        # exact class set match first\n",
        "        found = full_soup.find(snippet_tag.name, class_=snippet_tag.get(\"class\"))\n",
        "        if found: return found\n",
        "        # fallback: any element with any of those classes\n",
        "        for cls in snippet_tag.get(\"class\"):\n",
        "            found = full_soup.find(snippet_tag.name, class_=lambda c: c and cls in c)\n",
        "            if found: return found\n",
        "\n",
        "    text_content = snippet_tag.get_text(strip=True)\n",
        "    if text_content:\n",
        "        # match by tag + text content\n",
        "        found = full_soup.find(snippet_tag.name, string=re.compile(re.escape(text_content)))\n",
        "        if found: return found\n",
        "\n",
        "    return None  # not found\n",
        "\n",
        "# --- Resolve color from inline + stylesheet rules for a single Tag ---\n",
        "def resolve_color_for_tag(tag, css_rules: dict):\n",
        "    # Inline first (highest priority)\n",
        "    inline = parse_inline_style(tag.get(\"style\", \"\")) if tag.has_attr(\"style\") else {}\n",
        "    inline_color = inline.get(\"color\")\n",
        "    inline_bg   = inline.get(\"background-color\")\n",
        "\n",
        "    # Candidates (rough cascade): #id > .class > tag\n",
        "    candidates = []\n",
        "    if tag.has_attr(\"id\"):\n",
        "        candidates.append(f\"#{tag['id']}\")\n",
        "    if tag.has_attr(\"class\"):\n",
        "        for cls in tag[\"class\"]:\n",
        "            candidates.append(f\".{cls}\")\n",
        "            candidates.append(f\"{tag.name}.{cls}\")  # sometimes defined as tag.class\n",
        "    candidates.append(tag.name)\n",
        "\n",
        "    css_color = None\n",
        "    css_bg    = None\n",
        "    for sel in candidates:\n",
        "        if sel in css_rules:\n",
        "            # last matching selector wins (iterate in order above)\n",
        "            css_color = css_rules[sel].get(\"color\", css_color)\n",
        "            css_bg    = css_rules[sel].get(\"background-color\", css_bg)\n",
        "\n",
        "    # Tailwind-like utility classes (optional tokens only)\n",
        "    tailwind_tokens = []\n",
        "    if tag.has_attr(\"class\"):\n",
        "        tailwind_tokens = [c for c in tag[\"class\"] if c.startswith((\"text-\", \"bg-\", \"dark:text-\", \"dark:bg-\"))]\n",
        "\n",
        "    return {\n",
        "        \"inline_color\": inline_color,\n",
        "        \"inline_background_color\": inline_bg,\n",
        "        \"css_color\": css_color,\n",
        "        \"css_background_color\": css_bg,\n",
        "        \"class_color_tokens\": tailwind_tokens,\n",
        "    }\n",
        "\n",
        "# --- Pull everything together for your violation branch ---\n",
        "def extract_colors_for_affected_elements(affected_html_str: str, full_html: str):\n",
        "    # parse the snippet string into Tag objects\n",
        "    s_soup = BeautifulSoup(affected_html_str, \"html.parser\")\n",
        "    snippet_tags = s_soup.find_all()\n",
        "\n",
        "    # parse the full page once\n",
        "    full_soup = BeautifulSoup(full_html, \"html.parser\")\n",
        "    css_rules = parse_css_rules_from_style_tags(full_html)\n",
        "\n",
        "    results = []\n",
        "    for snip in snippet_tags:\n",
        "        # find the real element in the full DOM (so we get actual id/class/style)\n",
        "        real = locate_in_full_html(snip, full_soup) or snip  # fallback to snippet itself\n",
        "        colors = resolve_color_for_tag(real, css_rules)\n",
        "\n",
        "        results.append({\n",
        "            \"snippet\": str(snip),\n",
        "            \"resolved_element\": str(real),\n",
        "            **colors\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_css_variables(soup):\n",
        "    \"\"\"Extract all CSS variables from <style> blocks.\"\"\"\n",
        "    # soup = BeautifulSoup(full_html, \"html.parser\")\n",
        "    css_text = \"\\n\".join(st.get_text() for st in soup.find_all(\"style\"))\n",
        "    variables = {}\n",
        "\n",
        "    # Match --variable-name: value;\n",
        "    for var, val in re.findall(r'--([-\\w]+)\\s*:\\s*([^;]+);', css_text):\n",
        "        variables[f'--{var}'] = val.strip()\n",
        "    return variables\n",
        "\n",
        "def resolve_color_value(color_value, css_variables):\n",
        "    \"\"\"Replace var(--variable) with actual value if present.\"\"\"\n",
        "    if not color_value:\n",
        "        return None\n",
        "    # simple var() replacement\n",
        "    matches = re.findall(r'var\\((--[\\w-]+)\\)', color_value)\n",
        "    for var in matches:\n",
        "        if var in css_variables:\n",
        "            color_value = color_value.replace(f'var({var})', css_variables[var])\n",
        "    return color_value\n",
        "\n",
        "\n",
        "def download_images_from_snippets(snippets, save_dir=\"supplementary_images\"):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    paths = []\n",
        "\n",
        "    for idx, snippet in enumerate(snippets):\n",
        "        # Parse snippet to extract src\n",
        "        soup = BeautifulSoup(str(snippet), \"html.parser\")\n",
        "        img = soup.find(\"img\")\n",
        "        if not img or not img.get(\"src\"):\n",
        "            continue\n",
        "\n",
        "        url = img[\"src\"]\n",
        "\n",
        "        # Get file extension (default to .jpg)\n",
        "        ext = os.path.splitext(url.split(\"?\")[0])[1]\n",
        "        if not ext:\n",
        "            ext = \".jpg\"\n",
        "        # Build save path\n",
        "        filename = f\"image_{idx}{ext}\"\n",
        "        filepath = os.path.join(save_dir, filename)\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, timeout=15)\n",
        "            response.raise_for_status()\n",
        "            with open(filepath, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            paths.append(filepath)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading {url}: {e}\")\n",
        "\n",
        "    return paths\n",
        "\n",
        "\n",
        "async def extract_supplementary_info(row):\n",
        "    # Skip if supplementary_information already exists and is non-empty\n",
        "    if pd.notna(row.get(\"supplementary_information\")) and str(row.get(\"supplementary_information\")).strip():\n",
        "        return row[\"supplementary_information\"]\n",
        "\n",
        "    violation = row[\"violation_name\"]\n",
        "    html_file = row[\"html_file_name\"]\n",
        "\n",
        "    if \"content\" not in html_file_name:\n",
        "        html_file = \"/content/\"+str(html_file)\n",
        "\n",
        "    if not html_file.endswith(('.html', '.txt')):\n",
        "        html_file += '.html'\n",
        "\n",
        "    snippet = row[\"affected_html_elements\"]\n",
        "\n",
        "    try:\n",
        "        with open(html_file, 'r', encoding='utf-8') as f:\n",
        "            soup = BeautifulSoup(f, 'lxml')\n",
        "    except Exception as e:\n",
        "        return f\"HTML load error: {e}\"\n",
        "\n",
        "    # ---------- Violation-Specific Logic ----------\n",
        "    # Supplementary Information: Color Violations\n",
        "    if violation in ['color-only-distinction', 'color-contrast-enhanced', 'color-contrast']:\n",
        "        # --- Parse snippet HTML into tags ---\n",
        "        snippet_tags = row[\"affected_html_elements\"]\n",
        "        if type(snippet_tags) != list:\n",
        "            s_soup = BeautifulSoup(row[\"affected_html_elements\"], \"html.parser\")\n",
        "            snippet_tags = s_soup.find_all()\n",
        "\n",
        "        # --- Parse full HTML and CSS variables ---\n",
        "        # full_soup = BeautifulSoup(html, \"html.parser\")\n",
        "        with open(str(html_file), \"r\", encoding=\"utf-8\") as f:\n",
        "            html = f.read()\n",
        "\n",
        "        # Parse with BeautifulSoup\n",
        "        full_soup = BeautifulSoup(html, \"html.parser\")\n",
        "        css_variables = parse_css_variables(full_soup)\n",
        "\n",
        "        inline_color = set()\n",
        "        inline_background_color = set()\n",
        "        class_color_tokens = set()\n",
        "        # --- Iterate over snippets ---\n",
        "        for snip in snippet_tags:\n",
        "\n",
        "            # Try to find the same element in the full HTML (by id > class > text)\n",
        "            real = None\n",
        "            if snip.has_attr(\"id\"):\n",
        "                real = full_soup.find(id=snip[\"id\"])\n",
        "            if not real and snip.has_attr(\"class\"):\n",
        "                real = full_soup.find(snip.name, class_=snip.get(\"class\"))\n",
        "            if not real:\n",
        "                text_content = snip.get_text(strip=True)\n",
        "                if text_content:\n",
        "                    real = full_soup.find(snip.name, string=re.compile(re.escape(text_content)))\n",
        "            if not real:\n",
        "                real = snip  # fallback to snippet itself\n",
        "\n",
        "            # --- Extract inline color ---\n",
        "            inline_style = real.get(\"style\", \"\")\n",
        "            inline_colors = {}\n",
        "            for prop, val in re.findall(r'([-\\w]+)\\s*:\\s*([^;]+);?', inline_style):\n",
        "                prop = prop.lower()\n",
        "                inline_colors[prop] = resolve_color_value(val.strip(), css_variables)\n",
        "\n",
        "            # --- Extract class-based color tokens ---\n",
        "            class_colors = []\n",
        "            if real.has_attr(\"class\"):\n",
        "                class_colors = [c for c in real[\"class\"] if c.startswith((\"text-\", \"bg-\", \"dark:text-\", \"dark:bg-\"))]\n",
        "\n",
        "            if inline_colors.get(\"color\") or inline_colors.get(\"background-color\") or class_colors:\n",
        "                # \"affected_element\": str(snip),\n",
        "                # \"resolved_element\": str(real),\n",
        "                inline_color.add(inline_colors.get(\"color\"))\n",
        "                inline_background_color.add(inline_colors.get(\"background-color\"))\n",
        "                for i in class_colors:\n",
        "                    class_color_tokens.add(i)\n",
        "        return {\n",
        "            \"inline_color\":(inline_color),\n",
        "            \"inline_background_color\":(inline_background_color),\n",
        "            \"class_color_tokens\":(class_color_tokens)\n",
        "        }\n",
        "    # Supplementary Information: Image violations -> get image source from affected html and take a screenshot\n",
        "    if violation in [\n",
        "        \"image-alt\", \"input-image-alt\", \"image-alt-not-descriptive\",\n",
        "        \"image-redundant-alt\", \"area-alt\", \"frame-title\", \"frame-title-unique\",\n",
        "        \"object-alt\", \"role-img-alt\", \"svg-img-alt\", \"button-name\", \"input-button-name\"\n",
        "    ]:\n",
        "        # s_soup = BeautifulSoup(row[\"affected_html_elements\"], \"html.parser\")\n",
        "        # snippet_tags = s_soup.find_all()\n",
        "        downloaded_paths = download_images_from_snippets(row[\"affected_html_elements\"])\n",
        "        return downloaded_paths\n",
        "\n",
        "\n",
        "    # Supplementary Information: link-name\n",
        "    if violation in [\"link-name\",\"link-text-mismatch\"]:\n",
        "        link_info_list = []\n",
        "\n",
        "        snippets = row[\"affected_html_elements\"]\n",
        "        if type(snippets) != list:\n",
        "            snippets = re.findall(r'<a [^>]+>', snippet)\n",
        "\n",
        "        for snippet in snippets:\n",
        "            affected_html = snippet.strip()\n",
        "\n",
        "            href_match = re.search(r'href=[\"\\']([^\"\\']+)[\"\\']', affected_html)\n",
        "            target_match = re.search(r'target=[\"\\']([^\"\\']+)[\"\\']', affected_html)\n",
        "\n",
        "            href = href_match.group(1) if href_match else None\n",
        "            explicit_target = target_match.group(1).lower() if target_match else None\n",
        "\n",
        "            if not href or not href.startswith(\"http\"):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                async with async_playwright() as p:\n",
        "                    browser = await p.chromium.launch()\n",
        "                    page = await browser.new_page()\n",
        "                    await page.goto(href, timeout=15000)\n",
        "\n",
        "                    # Get page title\n",
        "                    page_title = await page.title()\n",
        "                    if not page_title:\n",
        "                        html = await page.content()\n",
        "                        soup = BeautifulSoup(html, \"html.parser\")\n",
        "                        page_title = soup.title.string.strip() if soup.title else \"No title found\"\n",
        "\n",
        "                    link_info_list.append(\n",
        "                        f\"The title of the target {href} link page: {page_title}\"\n",
        "                    )\n",
        "\n",
        "                    await browser.close()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing link '{href}': {e}\")\n",
        "\n",
        "        return \"\\n\\n\".join(link_info_list) if link_info_list else \"\"\n",
        "\n",
        "    # Supplementary Information: List\n",
        "    if violation == \"list\":\n",
        "        affected_html = snippet\n",
        "        full_list_html = get_full_list_html(soup, snippet)\n",
        "        if full_list_html:\n",
        "            return full_list_html\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "    elif any(v in violation for v in [\"ambiguous-heading\", \"empty-heading\", \"heading-order\"]):\n",
        "        headings = soup.find_all(re.compile(r'^h[1-6]$'))\n",
        "        results = []\n",
        "\n",
        "        for heading in headings:\n",
        "            if not heading.get_text(strip=True):\n",
        "                next_elements = []\n",
        "                sibling = heading.find_next_sibling()\n",
        "                while sibling and len(next_elements) < 3:\n",
        "                    if sibling.name in [\"p\", \"ul\", \"ol\", \"div\", \"section\"]:\n",
        "                        next_elements.append(str(sibling))\n",
        "                    sibling = sibling.find_next_sibling()\n",
        "                results.append(f\"{str(heading)}\\n\\n\" + \"\\n\\n\".join(next_elements))\n",
        "\n",
        "        return \"\\n\\n---\\n\\n\".join(results) if results else \"\"\n",
        "\n",
        "    elif \"empty-table-header\" in violation:\n",
        "        headers = soup.find_all(\"th\")\n",
        "        results = []\n",
        "\n",
        "        for th in headers:\n",
        "            if not th.get_text(strip=True):\n",
        "                next_elements = []\n",
        "                sibling = th.find_next_sibling()\n",
        "                while sibling and len(next_elements) < 3:\n",
        "                    if sibling.name in [\"td\", \"th\", \"tr\"]:\n",
        "                        next_elements.append(str(sibling))\n",
        "                    sibling = sibling.find_next_sibling()\n",
        "                results.append(f\"{str(th)}\\n\\n\" + \"\\n\\n\".join(next_elements))\n",
        "\n",
        "        return \"\\n\\n---\\n\\n\".join(results) if results else \"\"\n",
        "\n",
        "    elif \"page-has-heading-one\" in violation:\n",
        "        title_html = str(soup.title) if soup.title and soup.title.string else \"\"\n",
        "        h1_tags = soup.find_all(\"h1\")\n",
        "        h1_html = \"\\n\\n\".join(str(h) for h in h1_tags[:3]) if h1_tags else \"\"\n",
        "        return f\"{title_html}\\n\\n---\\n\\n{h1_html}\"\n",
        "\n",
        "    elif \"page-title-not-descriptive\" in violation:\n",
        "        title_html = str(soup.title) if soup.title and soup.title.string else \"\"\n",
        "        headings = soup.find_all(re.compile(r\"^h[1-6]$\"))\n",
        "        heading_html = [str(h) for h in headings[:10]]\n",
        "        return f\"{title_html}\\n\\n---\\n\\n\" + \"\\n\\n\".join(heading_html) if heading_html else title_html\n",
        "\n",
        "    elif \"document-title\" in violation:\n",
        "        title_html = str(soup.title) if soup.title and soup.title.string and soup.title.string.strip() else \"\"\n",
        "        # title_html = str(soup.title) if soup.title and soup.title.string.strip() else \"\"\n",
        "        headings = soup.find_all(re.compile(r\"^h[1-6]$\"))\n",
        "        heading_html = [str(h) for h in headings[:10]]\n",
        "        return f\"{title_html}\\n\\n---\\n\\n\" + \"\\n\\n\".join(heading_html) if heading_html else title_html\n",
        "\n",
        "    elif any(v in violation for v in [\n",
        "        \"duplicate-id\", \"duplicate-id-aria\", \"duplicate-id-active\",\n",
        "        \"landmark-no-duplicate-contentinfo\", \"landmark-no-duplicate-main\",\n",
        "        \"landmark-no-duplicate-banner\", \"landmark-unique\"\n",
        "    ]):\n",
        "        report = []\n",
        "\n",
        "        # Duplicate ID check\n",
        "        if any(v in violation for v in [\"duplicate-id\", \"duplicate-id-aria\", \"duplicate-id-active\"]):\n",
        "            id_map = {}\n",
        "            for tag in soup.find_all(attrs={\"id\": True}):\n",
        "                id_map.setdefault(tag[\"id\"], []).append(tag)\n",
        "\n",
        "            duplicates = {k: v for k, v in id_map.items() if len(v) > 1}\n",
        "            for dup_id, elements in list(duplicates.items())[:5]:\n",
        "                report.append(f\"ID '{dup_id}' is used {len(elements)} times:\")\n",
        "                for el in elements[:3]:\n",
        "                    snippet = str(el)\n",
        "                    report.append(snippet if len(snippet) <= 500 else snippet[:500] + \"...\")\n",
        "\n",
        "        # Duplicate landmarks\n",
        "        if \"landmark-no-duplicate-contentinfo\" in violation:\n",
        "            contentinfos = soup.find_all(role_or_tag(\"contentinfo\", \"footer\"))\n",
        "            if len(contentinfos) > 1:\n",
        "                report.append(f\"{len(contentinfos)} <footer> or role='contentinfo' elements found:\\n\" +\n",
        "                              \"\\n---\\n\".join(str(tag) for tag in contentinfos))\n",
        "\n",
        "        if \"landmark-no-duplicate-main\" in violation:\n",
        "            mains = soup.find_all(role_or_tag(\"main\", \"main\"))\n",
        "            if len(mains) > 1:\n",
        "                report.append(f\"{len(mains)} <main> or role='main' elements found:\\n\" +\n",
        "                              \"\\n---\\n\".join(str(tag) for tag in mains))\n",
        "\n",
        "        if \"landmark-no-duplicate-banner\" in violation:\n",
        "            banners = soup.find_all(role_or_tag(\"banner\", \"header\"))\n",
        "            if len(banners) > 1:\n",
        "                report.append(f\"{len(banners)} <header> or role='banner' elements found:\\n\" +\n",
        "                              \"\\n---\\n\".join(str(tag) for tag in banners))\n",
        "\n",
        "        if \"landmark-unique\" in violation:\n",
        "            roles = [\"main\", \"banner\", \"contentinfo\", \"navigation\", \"search\", \"complementary\", \"form\"]\n",
        "            for role in roles:\n",
        "                tags = soup.find_all(attrs={\"role\": role})\n",
        "                if len(tags) > 1:\n",
        "                    report.append(f\"Role '{role}' found {len(tags)} times:\\n\" +\n",
        "                                  \"\\n---\\n\".join(str(tag) for tag in tags))\n",
        "\n",
        "        return \"\\n\\n\".join(report) if report else \"\"\n",
        "\n",
        "    elif violation in [\n",
        "        \"landmark-main-is-top-level\", \"landmark-banner-is-top-level\", \"landmark-complementary-is-top-level\"\n",
        "    ]:\n",
        "        tag_map = {\n",
        "            \"landmark-main-is-top-level\": \"main\",\n",
        "            \"landmark-banner-is-top-level\": \"banner\",\n",
        "            \"landmark-complementary-is-top-level\": \"complementary\"\n",
        "        }\n",
        "        tag_role = tag_map.get(violation, \"main\")\n",
        "        container, error = get_landmark_container_for_tag(soup, tag_role)\n",
        "        return str(container) if container else \"\"\n",
        "\n",
        "    elif any(v in violation for v in [\n",
        "        \"lang-mismatch\", \"missing-lang-tag\", \"html-lang-valid\",\n",
        "        \"html-xml-lang-mismatch\", \"valid-lang\", \"html-has-lang\"\n",
        "    ]):\n",
        "        title = soup.title.string.strip() if soup.title and soup.title.string else \"No <title> tag or title is empty\"\n",
        "        headings = soup.find_all(re.compile(r'^h[1-6]$'))\n",
        "        heading_texts = [f\"{h.name.upper()}: {h.get_text(strip=True)}\" for h in headings if h.get_text(strip=True)]\n",
        "        return f\"Title: {title} | Headings: {' | '.join(heading_texts[:10])}\" if heading_texts else f\"Title: {title}\"\n",
        "\n",
        "    return \"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "5J3i4Pt2r5Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. AccessGuru Detect"
      ],
      "metadata": {
        "id": "MJe2dqpGsGcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5.b AcessGuru Detect for semantic accessibility violations\n",
        "\n",
        "For Semantic Detec, we will use the free model Qwen: https://openrouter.ai/qwen/qwen2.5-vl-72b-instruct:free to test. <br>\n",
        "**PLEASE NOTE** THAT THIS MODEL DOESN'T WORK WELL. PLEASE USE GPT-4o AS MENTIONED IN THE PAPER FOR AccessGuru Semantic Detection.\n",
        "\n",
        "\n",
        "### API Access Guide\n",
        "1. Open https://openrouter.ai/settings/keys\n",
        "2. Click on \"Create API key\"\n",
        "4. Create the api and copy the key to the clipboard"
      ],
      "metadata": {
        "id": "hkWWUrPOsg6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"sk-or-v1-xxxxxx\"  # Replace with your actual API key\n",
        "\n",
        "Openrouter_API_URL = \"https://openrouter.ai/api/v1/chat/completions\""
      ],
      "metadata": {
        "id": "JdjvV_k5tQQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def url_check_AndHtml(url):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch()\n",
        "        page = await browser.new_page()\n",
        "\n",
        "        try:\n",
        "            # Try navigating with a timeout\n",
        "            response = await page.goto(url, timeout=15000, wait_until=\"domcontentloaded\")\n",
        "\n",
        "            if not response:\n",
        "                print(f'No response for {url}. Please try another URL')\n",
        "                return \"not scraped\",None,None\n",
        "\n",
        "            status = response.status\n",
        "            final_url = page.url\n",
        "\n",
        "            if status >= 400:\n",
        "                print(f\"Failed to load {url} (status {status}). Please try another URL\")\n",
        "                return \"not scraped\",None,None\n",
        "\n",
        "            print(f\"Loaded {final_url} (status {status})\")\n",
        "            html = await page.content()\n",
        "            html_file_name = await save_html(html, url)  # Save the HTML\n",
        "            return \"scraped\",html,html_file_name\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {url}. Please try another URL\")\n",
        "            return \"not scraped\",None,None\n",
        "        finally:\n",
        "            await browser.close()\n",
        "\n",
        "def encode_image_to_data_url(image_path: Path) -> str:\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "        image_url = f\"data:image/png;base64,{encoded_image}\"\n",
        "    return image_url\n",
        "\n",
        "def generate_semantic_prompt(domain,url,taxonomy,html_text):\n",
        "    SEMANTIC_DETECT_PROMPT_TEMPLATE = \"\"\" You are a web accessibility expert. Your task is to detect semantic accessibility violations in the given HTML Web page. These violations are often not detectable by standard automated tools and require interpretation of the content meaning and user context.\n",
        "\n",
        "      A semantic violation occurs when:\n",
        "      - Attributes like alt text, language, or link/button labels are present but do not provide meaningful or accurate information,\n",
        "      - Visual or multimedia content is not described in a way that conveys its purpose to users with disabilities.\n",
        "\n",
        "      Use the information below to guide your analysis, you are operating on:\n",
        "      - The domain of the web page: {Insert Web page Domain}\n",
        "      - The URL of the web page: {Insert Web page URL}\n",
        "\n",
        "      You are provided with:\n",
        "      - The HTML code of the web page to analyze,\n",
        "      - The full semantic violation taxonomy. This taxonomy defines specific types of semantic violations, their descriptions,\n",
        "      - A screenshot of the rendered view of the web page.\n",
        "\n",
        "      {Semantic Violation Taxonomy}\n",
        "\n",
        "      {Insert HTML here}\n",
        "      {Insert Web page screenshot}\n",
        "\n",
        "\n",
        "      Now, review the HTML and supplementary data. List all semantic violations you detect, and for each:\n",
        "      1. Identify the affected HTML element. Enclose the exact\n",
        "      HTML snippet using the markers [START] and [END].\n",
        "      2. Specify the violation name.\n",
        "      \"\"\"\n",
        "\n",
        "    full_prompt = SEMANTIC_DETECT_PROMPT_TEMPLATE.replace(\n",
        "        \"{Insert Web page Domain}\", domain\n",
        "    ).replace(\n",
        "        \"{Insert Web page URL}\", url\n",
        "    ).replace(\n",
        "        \"{Semantic Violation Taxonomy}\", taxonomy\n",
        "    ).replace(\n",
        "        \"{Insert HTML here}\", html_text\n",
        "    ).replace(\n",
        "        \"{Insert Web page screenshot}\", \"(Screenshot attached below).\"\n",
        "    )\n",
        "    return full_prompt\n",
        "\n",
        "def generate_response(prompt_text,screenshot_data_url):\n",
        "    message = [{'role': 'system', 'content': \"You are a web accessibility expert.\"},\n",
        "              {'role': 'user', 'content': [\n",
        "                          {\"type\": \"text\", \"text\": prompt_text},\n",
        "                          {\n",
        "                              \"type\": \"image_url\",\n",
        "                              \"image_url\": {\n",
        "                                  \"url\": screenshot_data_url\n",
        "                              },\n",
        "                          },\n",
        "                        ],\n",
        "                    }\n",
        "              ]\n",
        "\n",
        "    response = requests.post(\n",
        "        Openrouter_API_URL,\n",
        "        headers={\n",
        "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        },\n",
        "        json={\n",
        "            \"model\": \"qwen/qwen2.5-vl-72b-instruct:free\",\n",
        "            \"messages\": message\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        chat_response = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return chat_response\n",
        "    else:\n",
        "        return f\"Error: {response.status_code}, {response.text}\"\n",
        "\n",
        "def post_process_response(web_URL, url_df, text: str, full_html: str):\n",
        "    \"\"\"\n",
        "    Extract all violations from LLM output into a list of dicts\n",
        "    with 'element' and 'violation' keys.\n",
        "    If the same violation_name occurs, append the element to its list.\n",
        "    \"\"\"\n",
        "    violations = []\n",
        "    violation_index = {}  # map violation_name -> index in violations list\n",
        "\n",
        "    # Regex to find each violation block (element + violation name)\n",
        "    pattern = re.compile(\n",
        "        r\"\\[START\\]\\s*```html\\s*(.*?)\\s*```\\s*\\[END\\].*?Violation Name:\\**\\s*([^\\n]+)\",\n",
        "        re.DOTALL | re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    matches = pattern.findall(text)\n",
        "    count = 0\n",
        "    web_URL_id = url_df[url_df[\"web_URL\"] == web_URL][\"web_URL_id\"].iloc[0]\n",
        "\n",
        "    for element, violation in matches:\n",
        "        element_clean = element.strip()\n",
        "\n",
        "        # Check if element exists in full HTML\n",
        "        if element_clean not in full_html:\n",
        "            continue  # skip if not found\n",
        "\n",
        "        violation_name = violation.strip().replace(\"`\", \"\")\n",
        "\n",
        "        try:\n",
        "            violation_description = violation_description_dict[violation_name]\n",
        "        except KeyError:\n",
        "            violation_description = \"\"\n",
        "\n",
        "        violation_impact = impact_dict.get(violation_name, \"Unknown\")\n",
        "\n",
        "        if violation_name in violation_index:\n",
        "            # Append to existing entry\n",
        "            idx = violation_index[violation_name]\n",
        "            violations[idx][\"affected_html_elements\"].append(element_clean)\n",
        "        else:\n",
        "            # Create new entry\n",
        "            new_id = f\"{web_URL_id}_{count}\"\n",
        "            violations.append({\n",
        "                \"id\": new_id,\n",
        "                \"web_URL\": web_URL,\n",
        "                \"affected_html_elements\": [element_clean],  # store as list\n",
        "                \"violation_name\": violation_name,\n",
        "                \"violation_description\": violation_description,\n",
        "                \"violation_description_url\": \"https://github.com/NadeenAhmad/AccessGuruLLM/blob/main/taxonomy_web_accessibility_violations.md\",\n",
        "                \"violation_impact\": violation_impact,\n",
        "                \"violation_score\": impactScore[violation_impact]\n",
        "            })\n",
        "            violation_index[violation_name] = len(violations) - 1\n",
        "            count += 1\n",
        "\n",
        "    return violations, count\n",
        "\n",
        "\n",
        "async def process_dataframe(df):\n",
        "    results = []\n",
        "    for _, row in df.iterrows():\n",
        "        supplementary_info = await extract_supplementary_info(row)\n",
        "        results.append(supplementary_info)\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "mRiBJIxLsh27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbBOL3vXsh0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6. Example Run\n"
      ],
      "metadata": {
        "id": "J9YAjqs0sWb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6.b. Semantic Example Run\n",
        "The input should have the following values for each keys:\n",
        "*   **web_URL_id** : Unique identifier for the URL\n",
        "*   **domain_category** : The domain of the website's subject area (Domains: Educational Platforms, Government and Public Services, News and Media, E-commerce, Streaming Platforms, Health and Wellness, Technology, Science and Research )\n",
        "*   **web_URL** : The URL of the webpage where the violation was found\n",
        "*   **screenshot_path**: Path to the captured screenshot of the Webpage. <br>\n",
        "Please take the screenshot of the webPage with a fixed viewport width of 1440 pixels and a height equal to the full scrollable length of the page, resulting in an image with a height up to 1440 times the viewport height, depending on page length.\n",
        "\n",
        "**Input dictionary example**:\n",
        "```\n",
        "{'web_URL_id':1, 'web_URL':'https://www.ki.uni-stuttgart.de/', 'domain_category': 'Educational Platforms','screenshot_path':\"/content/screencapture-ki-uni-stuttgart-de-2025-08-22-03_25_56.png\"}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "jRm5YVt8slWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sem_df = pd.read_csv(\"/content/violation_taxonomy.csv\")\n",
        "sem_df = sem_df[sem_df[\"Category\"]==\" Semantic\"]\n",
        "sem_violations = sem_df.violationnumberID.values\n",
        "sem_violations_list = [line.strip() for line in sem_violations if line.strip()]\n",
        "taxonomy = str(sem_violations_list)\n",
        "\n",
        "# RealWorld web_URL\n",
        "# After taking the screenshot of the webpage, PLEASE CHANGE THE screenshot_path.\n",
        "input_dict = {'web_URL_id':1, 'web_URL':'https://www.ki.uni-stuttgart.de/', 'domain_category': 'Educational Platforms','screenshot_path':\"/content/screencapture-ki-uni-stuttgart-de-2025-08-22-03_25_56.png\"}\n",
        "\n",
        "# Simple web_URL\n",
        "# After taking the screenshot of the webpage, PLEASE CHANGE THE screenshot_path.\n",
        "# input_dict = {'web_URL_id':1, 'web_URL':\"https://www.w3.org/WAI/content-assets/wcag-act-rules/testcases/qt1vmo/485f10faf222cd48fea2ab3ee79c2d354e51ea33.html\",'domain_category': 'Educational Platforms','screenshot_path':\"/content/Screenshot 2025-08-22 at 5.11.59 AM.png\"}\n",
        "\n",
        "url_df = pd.DataFrame([input_dict], columns=list(input_dict.keys()))\n",
        "urls = list(url_df[\"web_URL\"].values)\n",
        "\n",
        "output = pd.DataFrame()\n",
        "for url in urls:\n",
        "    scrape_status,html,html_file_name =  await url_check_AndHtml(url)\n",
        "\n",
        "    if scrape_status == \"not scraped\":\n",
        "       break\n",
        "    else:\n",
        "      url_df[\"scrape_status\"] = scrape_status\n",
        "      url_df[\"html_file_name\"] = html_file_name\n",
        "\n",
        "      screenshot_path = url_df[url_df[\"web_URL\"]==url][\"screenshot_path\"][0]\n",
        "      screenshot_data_url = encode_image_to_data_url(screenshot_path)\n",
        "\n",
        "      domain_category = url_df[url_df[\"web_URL\"]==url][\"domain_category\"][0]\n",
        "      prompt_text = generate_semantic_prompt(domain_category,url,taxonomy,html)\n",
        "      llm_response = generate_response(prompt_text,screenshot_data_url)\n",
        "\n",
        "      violations,violation_count = post_process_response(url,url_df,llm_response,html)\n",
        "      url_df[\"violation_count\"] = violation_count\n",
        "      for each_violation in violations:\n",
        "          df_dictionary = pd.DataFrame([each_violation])\n",
        "          output = pd.concat([output, df_dictionary], ignore_index=True)\n",
        "\n",
        "\n",
        "      if len(output)>0:\n",
        "          violation_df = pd.merge(output, url_df, on=\"web_URL\")\n",
        "          violation_df[\"wcag_reference\"] = violation_df[\"violation_name\"].map(mapping_dict)\n",
        "          # violation_df[\"supplementary_information\"]  = \"\"\n",
        "          violation_df[\"violation_category\"]  = \"Semantic\"\n",
        "          violation_df = violation_df[violation_df['violation_count'] != 0]\n",
        "\n",
        "\n",
        "violation_df.head()"
      ],
      "metadata": {
        "id": "YM5L18NVsnKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "8abc26f7-94bf-4929-b30d-0b978c6f222e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded https://www.ki.uni-stuttgart.de/ (status 200)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                           web_URL  \\\n",
              "0  1_0  https://www.ki.uni-stuttgart.de/   \n",
              "1  1_1  https://www.ki.uni-stuttgart.de/   \n",
              "\n",
              "                              affected_html_elements  \\\n",
              "0  [<img src=\"https://www.ki.uni-stuttgart.de/img...   \n",
              "1  [<a href=\"https://www.ki.uni-stuttgart.de/inst...   \n",
              "\n",
              "              violation_name  \\\n",
              "0  image-alt-not-descriptive   \n",
              "1         link-text-mismatch   \n",
              "\n",
              "                               violation_description  \\\n",
              "0  Inaccurate or misleading alternative text that...   \n",
              "1  Links fail to convey their purpose or are ambi...   \n",
              "\n",
              "                           violation_description_url violation_impact  \\\n",
              "0  https://github.com/NadeenAhmad/AccessGuruLLM/b...         critical   \n",
              "1  https://github.com/NadeenAhmad/AccessGuruLLM/b...          serious   \n",
              "\n",
              "   violation_score  web_URL_id        domain_category  \\\n",
              "0                5           1  Educational Platforms   \n",
              "1                4           1  Educational Platforms   \n",
              "\n",
              "                                     screenshot_path scrape_status  \\\n",
              "0  /content/screencapture-ki-uni-stuttgart-de-202...       scraped   \n",
              "1  /content/screencapture-ki-uni-stuttgart-de-202...       scraped   \n",
              "\n",
              "                                      html_file_name  violation_count  \\\n",
              "0  /content/html_pages_async/www_ki_uni-stuttgart...                2   \n",
              "1  /content/html_pages_async/www_ki_uni-stuttgart...                2   \n",
              "\n",
              "                                      wcag_reference violation_category  \n",
              "0                           [1.1.1 Non-text Content]           Semantic  \n",
              "1  [2.4.4 Link Purpose (In Context), 2.4.9 Link P...           Semantic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97fbfea5-43bd-4c48-8d40-a5f7619c77f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>web_URL</th>\n",
              "      <th>affected_html_elements</th>\n",
              "      <th>violation_name</th>\n",
              "      <th>violation_description</th>\n",
              "      <th>violation_description_url</th>\n",
              "      <th>violation_impact</th>\n",
              "      <th>violation_score</th>\n",
              "      <th>web_URL_id</th>\n",
              "      <th>domain_category</th>\n",
              "      <th>screenshot_path</th>\n",
              "      <th>scrape_status</th>\n",
              "      <th>html_file_name</th>\n",
              "      <th>violation_count</th>\n",
              "      <th>wcag_reference</th>\n",
              "      <th>violation_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_0</td>\n",
              "      <td>https://www.ki.uni-stuttgart.de/</td>\n",
              "      <td>[&lt;img src=\"https://www.ki.uni-stuttgart.de/img...</td>\n",
              "      <td>image-alt-not-descriptive</td>\n",
              "      <td>Inaccurate or misleading alternative text that...</td>\n",
              "      <td>https://github.com/NadeenAhmad/AccessGuruLLM/b...</td>\n",
              "      <td>critical</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Educational Platforms</td>\n",
              "      <td>/content/screencapture-ki-uni-stuttgart-de-202...</td>\n",
              "      <td>scraped</td>\n",
              "      <td>/content/html_pages_async/www_ki_uni-stuttgart...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.1.1 Non-text Content]</td>\n",
              "      <td>Semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_1</td>\n",
              "      <td>https://www.ki.uni-stuttgart.de/</td>\n",
              "      <td>[&lt;a href=\"https://www.ki.uni-stuttgart.de/inst...</td>\n",
              "      <td>link-text-mismatch</td>\n",
              "      <td>Links fail to convey their purpose or are ambi...</td>\n",
              "      <td>https://github.com/NadeenAhmad/AccessGuruLLM/b...</td>\n",
              "      <td>serious</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Educational Platforms</td>\n",
              "      <td>/content/screencapture-ki-uni-stuttgart-de-202...</td>\n",
              "      <td>scraped</td>\n",
              "      <td>/content/html_pages_async/www_ki_uni-stuttgart...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2.4.4 Link Purpose (In Context), 2.4.9 Link P...</td>\n",
              "      <td>Semantic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97fbfea5-43bd-4c48-8d40-a5f7619c77f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97fbfea5-43bd-4c48-8d40-a5f7619c77f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97fbfea5-43bd-4c48-8d40-a5f7619c77f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9e890c19-e41e-48e7-b647-b10fb7942af0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e890c19-e41e-48e7-b647-b10fb7942af0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9e890c19-e41e-48e7-b647-b10fb7942af0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "violation_df",
              "summary": "{\n  \"name\": \"violation_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1_1\",\n          \"1_0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"web_URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://www.ki.uni-stuttgart.de/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affected_html_elements\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"link-text-mismatch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Links fail to convey their purpose or are ambiguous.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_description_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://github.com/NadeenAhmad/AccessGuruLLM/blob/main/taxonomy_web_accessibility_violations.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_impact\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"serious\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"web_URL_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Educational Platforms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"screenshot_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/screencapture-ki-uni-stuttgart-de-2025-08-22-03_25_56.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scrape_status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"scraped\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"html_file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/html_pages_async/www_ki_uni-stuttgart_de_home.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wcag_reference\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Semantic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Supplementary Informations"
      ],
      "metadata": {
        "id": "-sZXabN46fg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# violation_df = pd.read_csv(\"/content/test.csv\") # to test the existing or saved files\n",
        "results = asyncio.run(process_dataframe(violation_df))\n",
        "violation_df[\"supplementary_information\"] = results\n",
        "violation_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "laSOEeCkoQkY",
        "outputId": "18c035e3-aa7f-4a4c-ee92-b4992ad9da84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                           web_URL  \\\n",
              "0  1_0  https://www.ki.uni-stuttgart.de/   \n",
              "1  1_1  https://www.ki.uni-stuttgart.de/   \n",
              "\n",
              "                              affected_html_elements  \\\n",
              "0  [<img src=\"https://www.ki.uni-stuttgart.de/img...   \n",
              "1  [<a href=\"https://www.ki.uni-stuttgart.de/inst...   \n",
              "\n",
              "              violation_name  \\\n",
              "0  image-alt-not-descriptive   \n",
              "1         link-text-mismatch   \n",
              "\n",
              "                               violation_description  \\\n",
              "0  Inaccurate or misleading alternative text that...   \n",
              "1  Links fail to convey their purpose or are ambi...   \n",
              "\n",
              "                           violation_description_url violation_impact  \\\n",
              "0  https://github.com/NadeenAhmad/AccessGuruLLM/b...         critical   \n",
              "1  https://github.com/NadeenAhmad/AccessGuruLLM/b...          serious   \n",
              "\n",
              "   violation_score  web_URL_id        domain_category  \\\n",
              "0                5           1  Educational Platforms   \n",
              "1                4           1  Educational Platforms   \n",
              "\n",
              "                                     screenshot_path scrape_status  \\\n",
              "0  /content/screencapture-ki-uni-stuttgart-de-202...       scraped   \n",
              "1  /content/screencapture-ki-uni-stuttgart-de-202...       scraped   \n",
              "\n",
              "                                      html_file_name  violation_count  \\\n",
              "0  /content/html_pages_async/www_ki_uni-stuttgart...                2   \n",
              "1  /content/html_pages_async/www_ki_uni-stuttgart...                2   \n",
              "\n",
              "                                      wcag_reference violation_category  \\\n",
              "0                           [1.1.1 Non-text Content]           Semantic   \n",
              "1  [2.4.4 Link Purpose (In Context), 2.4.9 Link P...           Semantic   \n",
              "\n",
              "                           supplementary_information  \n",
              "0  [supplementary_images/image_0.jpeg, supplement...  \n",
              "1  The title of the target https://www.ki.uni-stu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-778ccf1d-dba9-4a34-8008-7d7b36393bd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>web_URL</th>\n",
              "      <th>affected_html_elements</th>\n",
              "      <th>violation_name</th>\n",
              "      <th>violation_description</th>\n",
              "      <th>violation_description_url</th>\n",
              "      <th>violation_impact</th>\n",
              "      <th>violation_score</th>\n",
              "      <th>web_URL_id</th>\n",
              "      <th>domain_category</th>\n",
              "      <th>screenshot_path</th>\n",
              "      <th>scrape_status</th>\n",
              "      <th>html_file_name</th>\n",
              "      <th>violation_count</th>\n",
              "      <th>wcag_reference</th>\n",
              "      <th>violation_category</th>\n",
              "      <th>supplementary_information</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_0</td>\n",
              "      <td>https://www.ki.uni-stuttgart.de/</td>\n",
              "      <td>[&lt;img src=\"https://www.ki.uni-stuttgart.de/img...</td>\n",
              "      <td>image-alt-not-descriptive</td>\n",
              "      <td>Inaccurate or misleading alternative text that...</td>\n",
              "      <td>https://github.com/NadeenAhmad/AccessGuruLLM/b...</td>\n",
              "      <td>critical</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Educational Platforms</td>\n",
              "      <td>/content/screencapture-ki-uni-stuttgart-de-202...</td>\n",
              "      <td>scraped</td>\n",
              "      <td>/content/html_pages_async/www_ki_uni-stuttgart...</td>\n",
              "      <td>2</td>\n",
              "      <td>[1.1.1 Non-text Content]</td>\n",
              "      <td>Semantic</td>\n",
              "      <td>[supplementary_images/image_0.jpeg, supplement...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_1</td>\n",
              "      <td>https://www.ki.uni-stuttgart.de/</td>\n",
              "      <td>[&lt;a href=\"https://www.ki.uni-stuttgart.de/inst...</td>\n",
              "      <td>link-text-mismatch</td>\n",
              "      <td>Links fail to convey their purpose or are ambi...</td>\n",
              "      <td>https://github.com/NadeenAhmad/AccessGuruLLM/b...</td>\n",
              "      <td>serious</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Educational Platforms</td>\n",
              "      <td>/content/screencapture-ki-uni-stuttgart-de-202...</td>\n",
              "      <td>scraped</td>\n",
              "      <td>/content/html_pages_async/www_ki_uni-stuttgart...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2.4.4 Link Purpose (In Context), 2.4.9 Link P...</td>\n",
              "      <td>Semantic</td>\n",
              "      <td>The title of the target https://www.ki.uni-stu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778ccf1d-dba9-4a34-8008-7d7b36393bd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-778ccf1d-dba9-4a34-8008-7d7b36393bd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-778ccf1d-dba9-4a34-8008-7d7b36393bd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4960ff90-53ef-4004-b066-ac2a7435bc5e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4960ff90-53ef-4004-b066-ac2a7435bc5e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4960ff90-53ef-4004-b066-ac2a7435bc5e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "violation_df",
              "summary": "{\n  \"name\": \"violation_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1_1\",\n          \"1_0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"web_URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://www.ki.uni-stuttgart.de/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affected_html_elements\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"link-text-mismatch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Links fail to convey their purpose or are ambiguous.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_description_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://github.com/NadeenAhmad/AccessGuruLLM/blob/main/taxonomy_web_accessibility_violations.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_impact\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"serious\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"web_URL_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Educational Platforms\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"screenshot_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/screencapture-ki-uni-stuttgart-de-2025-08-22-03_25_56.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scrape_status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"scraped\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"html_file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/html_pages_async/www_ki_uni-stuttgart_de_home.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wcag_reference\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violation_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Semantic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"supplementary_information\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Result"
      ],
      "metadata": {
        "id": "uIdSjaK56aTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "violation_df.to_csv(\"AccessGuruDetectSemantic.csv\",index=False)"
      ],
      "metadata": {
        "id": "1Pbk_q1a2wAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjdStlhW6wCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TVnaV3BfuhCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZZq6Mu7wQeI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aK82LOJYaF1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPPyYUluZoAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OoU0svtnaAu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}